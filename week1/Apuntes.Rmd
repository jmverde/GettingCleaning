Getting and Cleaning the Data  Week 1
========================================================

**Fundamental dejar recogidos todos los pasos del procesado de los datos**

Code book:  explica las variables en el data set (muchas veces se pone aqui por ejemplo las unidades)


Hay que dejar y mantener la raw data como tal, sin haber hecho con ella absolutamente nada (sin quitar nada ni resumir nada), ni haber corrido nada de software en ella


### Tidy data

* Cada variable en una columna
* cada observacion en una linea
* una tabla por cada "tipo" de variable
* si hay varias tablas tiene que haber una columna que las permita linkar

* Primera fila con nombre de variables
* Nombres de variables claros y explicitos
* Un archivo por tabla

### Code book

Toda la informacion de las variables que no esta en los archivos,  UNIDADES!
Informacion sobre las decisiones que se tomaron al resumir
Informacion del dise??o experimental

Se suele incluir en el mismo sitio un experimental desing

### Instruction list: como pasar del principio al final

Lo suyo es que sea un script
imput: raw data
output: tidy data
No tiene que tener parametros

Si no puede ser un script hay que dar unas instrucciones explicitas


Downloading Files
-----------------

#### Manejo de directorios

getwd() y setwd() son tus amigos,  se puede usar absoluto o relativo partiendo de ./  y las rutas se meten como cadenas de texto
Ojo, en guindows hay que usar \

ver si existe un directorio  file.exists() 
crear: dir.create("dirname") 

exemplio 

if(!file.exists("data")){
dir.create("data")
}


### descargar de internet

download.file()  viene bien usarlo para asegurar reproducibilidad 
parametros  *url*  *destfile* *method* 
cuando hay problemas de https hay que usar  method="curl" por que

Importante dejar algo asi como Fechadownload<-date() y guardarlo en algun sitio, por que los archivos tienden a cambiar
A veces es mejor dejar esto fuera del script y dejar dicho en las instructions como se hizo (por no descargarte todos los dias cuatro gigas)

### Cargar archivos locales 

read.table()  es la mas flexible, pero hay que pasarle muchos parametros, tarda tiempo y ademas necesita cargar todo en RAM
parametros importantes  file, header, sep, row.names, nrows, con nrows dices cuantas lineas quieres leer

read.csv pone el separador como "," y header en true

mas valores  quote: si hay comillas na.strings si el na esta representado por otra cosa (hay en col de datos que viene con -1 ...) y skip para decir cuantas lineas quieres saltarte al principio

si hay problemas  quote="" arregla bastante cosas
```{r}
```

### Archivos de Excell (xlsx)
Lo mas comodo es usar el paquete xlsx con library y despues usar read.xlsx y read.xlsx2, siendo el segundo mas rapido, pero mejor usarlo solo con archivos completos 

parametros importantes sheetIndex y header=TRUE

se pueden usar colIndex y rowIndex para hacer un subset de lo que se quiere leer

tambien tenemos write.xlsx

Mirar tambien XLconect

### Archivos XML 

como siempre tenemos nuestras tags que abren y cierran delimitando campos o solo cierran (por ejemplo saltos de linea) (las que solo cierran acaban en slash en vez de empezar como las normales de cierre) 
Dentro de la tag tambien puede haber info, que son atributos del campo

Se usa la biblioteca XML
tnemos xmlTreeParse que nos manda a una estrucutura de datos el xml
tenemos utiles el xmlRoot que devuelve el root node (que viene siendo todo)
xmlName

Es importatne usar el useInterlanNodes=TRUE
names da los nombres de los elementos en le siguiente nivel

para acceder a los elementos se usa [[n]]  y se puede seguir bajando niveles con mas [[]]

Sacar cosas del la estructura:  usar xmlSapply,  por ejemplo para sacar los valores de todo se haria xmlSapply(nodo,xmlValue)

Para acceder hay que usar XPath 
/node  top level
//node  nodo a cualquier nivel
nodo[@atrr name]  nodo con un nombre de atributo
nodo[@atrname ="pepe"] nodo que cumple esa condicion 


Por ejemplo, sacar todos los valores de nombres de subnodo
xpathSapply(datos,"//name",xmlValue)
sacar todos los precios

xpathSapply(datos,"//price",xmlValue)


Se pueden hacer cosas muy parecidas con html partiendo de la funcion 
htmlTreeParse solo que hay que poner una url  (y usar useInternal=TRUE) 
y despues se puede usar el xpathSapply 


### Archivos JSON

La idea es parecida a xml
los objetos se guardan como doble, strings, bool,array [] y objetos (como los dict de python, en {} y por pares, no ordenados, key:value) 

se usa el package jsonlite 
se puede usar fromJSON(url) 

names:  top level variables y se puede ir bajando niveles a base de json$equipos$primeradiv

se puede usar toJSON para guardar data frames en JSON  hbria que tener una buena razon para no usar pretty=TRUE 


### The data.table package

todas las funciones que aplican sobre data.frame funcionan en data.table (por que hereda de esta)
mas rapido por que va en C

library(data.table) 

tables() te dice cuanta memoria esta ocupada por cada tabla 

el sub set es como en un data frame 

si se hace subset con un solo indice lo hace directamente a rows (con lo que no haria falta la , final) 

subset columnas 

cualquier cosa que pasas despues de la coma es una expresion,  que es una coleccion de ordenes metidas en {}, por ejemplo pondriamos list(mean(x),sum(z)) y haria la media de la columna que se llama x y la suma de la que se llama z  (y no hace falta poner las comillas) 

a??adir nueva columna DT[,z:=expresion]  ojo, que si repites numero lo pisas

ojo, no se hacen copias distintas en memoria si no se usa copy de forma explicita 

se podrian hacer pasos intermedios DT[,m:={tmp<-(x+y);log2(tmp+2)} 

se pueden hacer evaliaciones DT[,x:a>0] 
se puede ordenar con un by=

Variables especiales:
.N numero de veces que aparece cada variable DT[,.N,by=x] 

Keys,  para ordenar mucho mas rapido  setKey(DT,variable)  DT['valor del key'] da los que hacen falta 

tambien se puede usar un setkey y despues usar la misma key para un merge(DT1,DT2) 

Fast Reading 

Es mejor usar data.table para leer rapido de disco 


Para usar archis que no se vayan a guardar se puede usar tempfile() 

usar para grabar write.table() y despues se puede usar fread para leerlas
y usar sep="\t" para guardar con tabuladores que es lo que lee por defecto fread